{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "60b90749ba814f6c8c29c3ece76a461b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3302,
    "execution_start": 1679330289172,
    "source_hash": "7b811129",
    "tags": []
   },
   "source": [
    "# Tour & Travels Customer Churn Prediction\n",
    "### https://www.kaggle.com/datasets/tejashvi14/tour-travels-customer-churn-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import learning_curve, validation_curve, train_test_split, KFold, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import loguniform, beta, uniform\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "\n",
    "import missingno as msno # credo non necessario\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy.stats as stats # aggiunta\n",
    "from scipy.stats import binom # da vrf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per eventuale verifica delle versioni delle librerie\n",
    "# ESEMPIO: print(pd.__version__, np.__version__, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.read_csv('Customertravel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db #solo per check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sembrerebbe che non ci siano missing value, ma..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#... da descibe si nota che l'attributo \"FrequentFlyer\" che dovrebbe essere binario del tipo Yes/No, in realtÃ  presenta\n",
    "# 3 distinte valorizzaioni ==> esiste un terzo valore = \"No Record\" ATTENZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['FrequentFlyer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facciamo innanzitutto lo split X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.split(db,[-1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X # solo per check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSTRUZIONE DELLA CLASSE TRANSFORM (non considerare per il momento questa classe!!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoRecordTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "      \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        freq_Yes = X.value_counts()['Yes']\n",
    "        freq_YesNo = X.value_counts()['Yes'] + X.value_counts()['No']\n",
    "        prob_Yes = freq_Yes/freq_YesNo\n",
    "        freq_NoRecord = X.value_counts()['No Record'] \n",
    "        \n",
    "        fair_coin_flips = stats.binom.rvs(n=1,                  # Number of flips per trial\n",
    "                                          p=prob_Yes,           # Success probability\n",
    "                                          size=freq_NoRecord,   # Number of trials\n",
    "                                          random_state=100)  \n",
    "        \n",
    "        NoRecord_impute = np.empty(freq_NoRecord, dtype=object)\n",
    "        for i, value in enumerate(fair_coin_flips):\n",
    "            if value == 0:\n",
    "                NoRecord_impute[i] = 'No'\n",
    "        else:\n",
    "                NoRecord_impute[i] = 'Yes'\n",
    "        \n",
    "        X_imputed = np.zeros(len(X), dtype=object)\n",
    "        k = -1\n",
    "        for i in range(len(X)):\n",
    "            if X[i] == 'No Record':\n",
    "                k += 1\n",
    "                X_imputed[i] = NoRecord_impute[k]\n",
    "            else:\n",
    "                X_imputed[i] = X[i]\n",
    "        return pd.Series(X_imputed)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return ['FrequentFlyer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSTRUZIONE DELLA PAPELINE DI TRASFORMAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_FrequentFlyer = Pipeline([\n",
    "#    ('custom', NoRecordTransformer()),\n",
    "#    ('hot', OneHotEncoder(categories='auto',drop='first',handle_unknown='ignore'))\n",
    "#])\n",
    "\n",
    "\n",
    "pipeline_FrequentFlyer = Pipeline([\n",
    "   ('hot', OneHotEncoder(categories='auto', drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "final_transformation = ColumnTransformer(transformers=[\n",
    "    ('Age', StandardScaler(), ['Age']),\n",
    "    ('FrequentFlyer', pipeline_FrequentFlyer, ['FrequentFlyer']),\n",
    "    ('AnnualIncomeClass', OrdinalEncoder(categories=[['Low Income','Middle Income','High Income']]), \n",
    "         ['AnnualIncomeClass']),    \n",
    "    ('ServicesOpted', MinMaxScaler(), ['ServicesOpted']),\n",
    "    ('AccountSyncedToSocialMedia', OneHotEncoder(categories='auto',drop='first',handle_unknown='ignore'), \n",
    "         ['AccountSyncedToSocialMedia']),\n",
    "    ('BookedHotelOrNot', OneHotEncoder(categories='auto',drop='first',handle_unknown='ignore'), \n",
    "         ['BookedHotelOrNot'])   \n",
    "],\n",
    "remainder='drop',\n",
    "verbose_feature_names_out=False,\n",
    "sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING AND TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = IMBPipeline([\n",
    "    ('trans', final_transformation),\n",
    "    ('sampler', SMOTE()),\n",
    "    ('dim_reduction', PCA(n_components=0.8)),\n",
    "    ('classifier', Perceptron())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "82120c7406c24880a3f63bb8ac349bb3",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
